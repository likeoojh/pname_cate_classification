1. 정제
refine.py, refine.reex.txt 로 특수문자제거 및 필요없는 단어들 대체.. 여기서는 가장 기본만
$ python refine.py refine.regex.txt 1 < pname.cate1.unique.tsv  > pname.cate1.unique.refined.tsv

2. 토큰화
tokenize.sh 활용, 토근화하여 저장
$ ./tokenize.sh pname.cate1.unique.refined.tsv pname.cate1.unique.refined.tok.tsv

3. train, test 분리 저장
- shuffling
$ gshuf < pname.cate1.unique.refined.tok.tsv > pname.cate1.unique.refined.tok.shuf.tsv

- 0.8 train, 0.2 test 저장
$ head -n 25000 pname.cate1.unique.refined.tok.shuf.tsv > pname.cate1.unique.refined.tok.shuf.train.tsv 
$ tail -n 7117 pname.cate1.unique.refined.tok.shuf.tsv > pname.cate1.unique.refined.tok.shuf.test.tsv 

- 확인
$ wc -l ./pname.cate1.unique.refined.tok.shuf.*

4. 모델링
(rnn, cnn 학습)$ python train.py --model_fn ./model_results/review.pth --train_fn ./data/pname.cate1.unique.refined.tok.shuf.train.tsv  --word_vec_size 256 --rnn --hidden_size 512 --n_layers 4 --cnn --window_sizes 3 4 5 6 7 8 --n_filters 128 128 128 128 128 128 --gpu_id 0 --n_epochs 3 --batch_size 80 --min_vocab_freq 1ain_fn ../review.sorted.uniq.refined.tok.shuf.train.tsv --gpu_id -1 --batch_size 128 --min_vocab_freq 3 --n_epochs 10 --word_vec_size 256 --rnn --hidden_size 512 --n_layers 4 --cnn --window
_sizes 3 4 5 6 7 8 --n_filters 128 128 128 128 128 128

(테스트 샘플 추론)
$ cut -f2 ./data/pname.cate1.unique.refined.tok.shuf.test.tsv | shuf | head -n 10 | python ./classify.py --model_fn ./model_results/review.pth --gpu_id -1
$ echo "나이키 에어 맥스" | mecab -O wakati | python ./classify.py --model_fn ./model_results/review.pth

(테스트 전체 저장)
$ cut -f2 ../review.sorted.uniq.refined.tok.shuf.test.tsv |  python ./classify.py --model_fn ../models/review.pth --gpu_id -1 > ddd.tsv

작업환경 세팅
$ python3.8 -m virtualenv env
$ source env/bin/activate
